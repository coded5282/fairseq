slurm_config: big
task_type: local_predict
dataset:
  split: test
  video_processor: VideoProcessor
  aligner: YTJActionSegmentationAligner
  bert_name: bert-base-uncased
  test_path: data/open-surgery-yt/surgery_action_labels_filtered.json
  meta_processor: YTJActionSegmentationMetaProcessor
  vfeat_dir: data/open-surgery-yt/feat/feat_how2_s3d
  text_processor: YTJActionSegmentationTextProcessor
  num_iso_layer: 12
  sliding_window: 16
  sliding_window_size: 32
  max_video_len: 32
  max_len: 96
fairseq:
  dataset:
    batch_size: 1
    valid_subset: test
    num_workers: 2
  common_eval:
    path: runs/retri/youtube-jomi/checkpoint_best.pt
model:
  model_cls: MMFusionSeparate
  mm_encoder_cls: null
  video_encoder_cls: MMBertForEncoder
  text_encoder_cls: BertModel
  num_hidden_video_layers: 6
eval:
  save_path: runs/retri/videoclip/open_surgery_yt_zs/eval
metric: COINActionSegmentationMetric
predictor: COINZSPredictor
